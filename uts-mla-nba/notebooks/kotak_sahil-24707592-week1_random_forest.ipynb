{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ccda125",
   "metadata": {},
   "source": [
    "# NBA Draft Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f277d4",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a6f76d",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8051905d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil Kotak\\AppData\\Local\\Temp\\ipykernel_8464\\39747410.py:4: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_data = pd.read_csv('../data/raw//train.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metadata = pd.read_csv('../data/raw/metadata.csv')\n",
    "train_data = pd.read_csv('../data/raw//train.csv')\n",
    "test_data = pd.read_csv('../data/raw//test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ccec45",
   "metadata": {},
   "source": [
    "### Handle non-numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c89b1a13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Handle non-numeric values in 'num' column\n",
    "median_value = pd.to_numeric(train_data['num'], errors='coerce').median()\n",
    "train_data['num'] = pd.to_numeric(train_data['num'], errors='coerce').fillna(median_value)\n",
    "test_data['num'] = pd.to_numeric(test_data['num'], errors='coerce').fillna(median_value)\n",
    "\n",
    "# Convert 'yr' column to ordinal numbers\n",
    "year_mapping = {'Fr': 1, 'So': 2, 'Jr': 3, 'Sr': 4}\n",
    "train_data['yr'] = train_data['yr'].map(year_mapping)\n",
    "test_data['yr'] = test_data['yr'].map(year_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff36a8e8",
   "metadata": {},
   "source": [
    "### Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6701ec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop columns with more than 50% missing data\n",
    "columns_to_drop = ['pick', 'Rec_Rank', 'dunks_ratio', 'ht']\n",
    "train_data.drop(columns_to_drop, axis=1, inplace=True)\n",
    "test_data.drop(columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# Impute missing values with median for remaining columns with missing data\n",
    "columns_to_impute = ['mid_ratio', 'rim_ratio', 'rimmade', 'rimmade_rimmiss', 'midmade', 'midmade_midmiss',\n",
    "                     'dunksmade', 'dunksmiss_dunksmade', 'num', 'ast_tov', 'yr', 'obpm', 'dgbpm',\n",
    "                     'ogbpm', 'gbpm', 'dbpm', 'adrtg', 'bpm', 'stops', 'dporpag', 'drtg', 'mp', 'oreb',\n",
    "                     'dreb', 'treb', 'ast', 'stl', 'blk', 'pts']\n",
    "\n",
    "for column in columns_to_impute:\n",
    "    median_value = train_data[column].median()\n",
    "    train_data[column].fillna(median_value, inplace=True)\n",
    "    test_data[column].fillna(median_value, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed78ad6d",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bd62343",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9836798742823925"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Split the data into train and validation sets\n",
    "X = train_data.drop(['player_id', 'drafted'], axis=1)\n",
    "y = train_data['drafted']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('model', model)])\n",
    "\n",
    "# Preprocessing of training data, train model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "val_preds = pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Get the AUROC score\n",
    "val_score = roc_auc_score(y_val, val_preds)\n",
    "val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d5ab9f",
   "metadata": {},
   "source": [
    "## Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "358aa1a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'submissions.csv'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on the test data\n",
    "test_preds = pipeline.predict_proba(test_data.drop('player_id', axis=1))[:, 1]\n",
    "\n",
    "# Create a submission DataFrame\n",
    "submission = pd.DataFrame({'player_id': test_data['player_id'], 'drafted': test_preds})\n",
    "\n",
    "# Save the submission DataFrame to a CSV file\n",
    "submission_path = 'submissions.csv'\n",
    "submission.to_csv(submission_path, index=False)\n",
    "submission_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d494238-a039-4224-90f5-43434de7d2c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85e24c99-4226-4795-9821-dc0a1bac683f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>team</td>\n",
       "      <td>Name of team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>conf</td>\n",
       "      <td>Name of conference</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>GP</td>\n",
       "      <td>Games played</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Min_per</td>\n",
       "      <td>Player's percentage of available team minutes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>ORtg</td>\n",
       "      <td>ORtg - Offensive Rating (available since the 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>66</td>\n",
       "      <td>stl</td>\n",
       "      <td>STL - Steals (available since the 1973-74 seas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>67</td>\n",
       "      <td>blk</td>\n",
       "      <td>BLK - Blocks (available since the 1973-74 seas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>68</td>\n",
       "      <td>pts</td>\n",
       "      <td>PTS - Points</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>69</td>\n",
       "      <td>player_id</td>\n",
       "      <td>Unique identifier of player</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>70</td>\n",
       "      <td>drafted</td>\n",
       "      <td>Target - Was the player drafted at the end of ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature       name                                        description\n",
       "0         1       team                                       Name of team\n",
       "1         2       conf                                 Name of conference\n",
       "2         3         GP                                       Games played\n",
       "3         4    Min_per  Player's percentage of available team minutes ...\n",
       "4         5       ORtg  ORtg - Offensive Rating (available since the 1...\n",
       "..      ...        ...                                                ...\n",
       "59       66        stl  STL - Steals (available since the 1973-74 seas...\n",
       "60       67        blk  BLK - Blocks (available since the 1973-74 seas...\n",
       "61       68        pts                                       PTS - Points\n",
       "62       69  player_id                        Unique identifier of player\n",
       "63       70    drafted  Target - Was the player drafted at the end of ...\n",
       "\n",
       "[64 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load metadata.csv\n",
    "metadata_df = pd.read_csv(\"../data/raw/metadata.csv\")\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c20c379e-5806-45e3-a295-3a8541446e1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sahil Kotak\\AppData\\Local\\Temp\\ipykernel_1592\\3403509580.py:2: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv(\"../data/raw/train.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>conf</th>\n",
       "      <th>GP</th>\n",
       "      <th>Min_per</th>\n",
       "      <th>Ortg</th>\n",
       "      <th>usg</th>\n",
       "      <th>eFG</th>\n",
       "      <th>TS_per</th>\n",
       "      <th>ORB_per</th>\n",
       "      <th>DRB_per</th>\n",
       "      <th>...</th>\n",
       "      <th>dgbpm</th>\n",
       "      <th>oreb</th>\n",
       "      <th>dreb</th>\n",
       "      <th>treb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>pts</th>\n",
       "      <th>player_id</th>\n",
       "      <th>drafted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>South Alabama</td>\n",
       "      <td>SB</td>\n",
       "      <td>26</td>\n",
       "      <td>29.5</td>\n",
       "      <td>97.3</td>\n",
       "      <td>16.6</td>\n",
       "      <td>42.5</td>\n",
       "      <td>44.43</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.941150</td>\n",
       "      <td>0.1923</td>\n",
       "      <td>0.6154</td>\n",
       "      <td>0.8077</td>\n",
       "      <td>1.1923</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>3.8846</td>\n",
       "      <td>7be2aead-da4e-4d13-a74b-4c1e692e2368</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Utah St.</td>\n",
       "      <td>WAC</td>\n",
       "      <td>34</td>\n",
       "      <td>60.9</td>\n",
       "      <td>108.3</td>\n",
       "      <td>14.9</td>\n",
       "      <td>52.4</td>\n",
       "      <td>54.48</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.247934</td>\n",
       "      <td>0.6765</td>\n",
       "      <td>1.2647</td>\n",
       "      <td>1.9412</td>\n",
       "      <td>1.8235</td>\n",
       "      <td>0.4118</td>\n",
       "      <td>0.2353</td>\n",
       "      <td>5.9412</td>\n",
       "      <td>61de55d9-1582-4ea4-b593-44f6aa6524a6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Florida</td>\n",
       "      <td>BE</td>\n",
       "      <td>27</td>\n",
       "      <td>72.0</td>\n",
       "      <td>96.2</td>\n",
       "      <td>21.8</td>\n",
       "      <td>45.7</td>\n",
       "      <td>47.98</td>\n",
       "      <td>2.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.883163</td>\n",
       "      <td>0.6296</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>2.9630</td>\n",
       "      <td>1.9630</td>\n",
       "      <td>0.4815</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>12.1852</td>\n",
       "      <td>efdc4cfc-9dd0-4bf8-acef-7273e4d5b655</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pepperdine</td>\n",
       "      <td>WCC</td>\n",
       "      <td>30</td>\n",
       "      <td>44.5</td>\n",
       "      <td>97.7</td>\n",
       "      <td>16.0</td>\n",
       "      <td>53.6</td>\n",
       "      <td>53.69</td>\n",
       "      <td>4.1</td>\n",
       "      <td>9.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.393459</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>1.4333</td>\n",
       "      <td>2.1333</td>\n",
       "      <td>1.1000</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>0.1333</td>\n",
       "      <td>4.9333</td>\n",
       "      <td>14f05660-bb3c-4868-b3dd-09bcdb64279d</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pacific</td>\n",
       "      <td>BW</td>\n",
       "      <td>33</td>\n",
       "      <td>56.2</td>\n",
       "      <td>96.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>52.8</td>\n",
       "      <td>54.31</td>\n",
       "      <td>8.3</td>\n",
       "      <td>18.6</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.668318</td>\n",
       "      <td>1.4242</td>\n",
       "      <td>3.3030</td>\n",
       "      <td>4.7273</td>\n",
       "      <td>0.8485</td>\n",
       "      <td>0.4545</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>7.5758</td>\n",
       "      <td>a58db52f-fbba-4e7b-83d0-371efcfed039</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            team conf  GP  Min_per   Ortg   usg   eFG  TS_per  ORB_per   \n",
       "0  South Alabama   SB  26     29.5   97.3  16.6  42.5   44.43      1.6  \\\n",
       "1       Utah St.  WAC  34     60.9  108.3  14.9  52.4   54.48      3.8   \n",
       "2  South Florida   BE  27     72.0   96.2  21.8  45.7   47.98      2.1   \n",
       "3     Pepperdine  WCC  30     44.5   97.7  16.0  53.6   53.69      4.1   \n",
       "4        Pacific   BW  33     56.2   96.5  22.0  52.8   54.31      8.3   \n",
       "\n",
       "   DRB_per  ...     dgbpm    oreb    dreb    treb     ast     stl     blk   \n",
       "0      4.6  ... -1.941150  0.1923  0.6154  0.8077  1.1923  0.3462  0.0385  \\\n",
       "1      6.3  ... -0.247934  0.6765  1.2647  1.9412  1.8235  0.4118  0.2353   \n",
       "2      8.0  ... -0.883163  0.6296  2.3333  2.9630  1.9630  0.4815  0.0000   \n",
       "3      9.4  ... -0.393459  0.7000  1.4333  2.1333  1.1000  0.5667  0.1333   \n",
       "4     18.6  ... -0.668318  1.4242  3.3030  4.7273  0.8485  0.4545  0.3333   \n",
       "\n",
       "       pts                             player_id  drafted  \n",
       "0   3.8846  7be2aead-da4e-4d13-a74b-4c1e692e2368      0.0  \n",
       "1   5.9412  61de55d9-1582-4ea4-b593-44f6aa6524a6      0.0  \n",
       "2  12.1852  efdc4cfc-9dd0-4bf8-acef-7273e4d5b655      0.0  \n",
       "3   4.9333  14f05660-bb3c-4868-b3dd-09bcdb64279d      0.0  \n",
       "4   7.5758  a58db52f-fbba-4e7b-83d0-371efcfed039      0.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load train.csv\n",
    "train_df = pd.read_csv(\"../data/raw/train.csv\")\n",
    "\n",
    "# Display the first few rows of the train.csv data\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93984687-9f4a-479c-892e-c5fba4168998",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56091, 64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed9eec0d-d4f4-4813-9347-b7029fd18776",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 56091 entries, 0 to 56090\n",
      "Data columns (total 64 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   team                 56091 non-null  object \n",
      " 1   conf                 56091 non-null  object \n",
      " 2   GP                   56091 non-null  int64  \n",
      " 3   Min_per              56091 non-null  float64\n",
      " 4   Ortg                 56091 non-null  float64\n",
      " 5   usg                  56091 non-null  float64\n",
      " 6   eFG                  56091 non-null  float64\n",
      " 7   TS_per               56091 non-null  float64\n",
      " 8   ORB_per              56091 non-null  float64\n",
      " 9   DRB_per              56091 non-null  float64\n",
      " 10  AST_per              56091 non-null  float64\n",
      " 11  TO_per               56091 non-null  float64\n",
      " 12  FTM                  56091 non-null  int64  \n",
      " 13  FTA                  56091 non-null  int64  \n",
      " 14  FT_per               56091 non-null  float64\n",
      " 15  twoPM                56091 non-null  int64  \n",
      " 16  twoPA                56091 non-null  int64  \n",
      " 17  twoP_per             56091 non-null  float64\n",
      " 18  TPM                  56091 non-null  int64  \n",
      " 19  TPA                  56091 non-null  int64  \n",
      " 20  TP_per               56091 non-null  float64\n",
      " 21  blk_per              56091 non-null  float64\n",
      " 22  stl_per              56091 non-null  float64\n",
      " 23  ftr                  56091 non-null  float64\n",
      " 24  yr                   55799 non-null  object \n",
      " 25  ht                   55993 non-null  object \n",
      " 26  num                  51401 non-null  object \n",
      " 27  porpag               56091 non-null  float64\n",
      " 28  adjoe                56091 non-null  float64\n",
      " 29  pfr                  56091 non-null  float64\n",
      " 30  year                 56091 non-null  int64  \n",
      " 31  type                 56091 non-null  object \n",
      " 32  Rec_Rank             17036 non-null  float64\n",
      " 33  ast_tov              51901 non-null  float64\n",
      " 34  rimmade              50010 non-null  float64\n",
      " 35  rimmade_rimmiss      50010 non-null  float64\n",
      " 36  midmade              50010 non-null  float64\n",
      " 37  midmade_midmiss      50010 non-null  float64\n",
      " 38  rim_ratio            46627 non-null  float64\n",
      " 39  mid_ratio            46403 non-null  float64\n",
      " 40  dunksmade            50010 non-null  float64\n",
      " 41  dunksmiss_dunksmade  50010 non-null  float64\n",
      " 42  dunks_ratio          25298 non-null  float64\n",
      " 43  pick                 1386 non-null   float64\n",
      " 44  drtg                 56047 non-null  float64\n",
      " 45  adrtg                56047 non-null  float64\n",
      " 46  dporpag              56047 non-null  float64\n",
      " 47  stops                56047 non-null  float64\n",
      " 48  bpm                  56047 non-null  float64\n",
      " 49  obpm                 56047 non-null  float64\n",
      " 50  dbpm                 56047 non-null  float64\n",
      " 51  gbpm                 56047 non-null  float64\n",
      " 52  mp                   56053 non-null  float64\n",
      " 53  ogbpm                56047 non-null  float64\n",
      " 54  dgbpm                56047 non-null  float64\n",
      " 55  oreb                 56053 non-null  float64\n",
      " 56  dreb                 56053 non-null  float64\n",
      " 57  treb                 56053 non-null  float64\n",
      " 58  ast                  56053 non-null  float64\n",
      " 59  stl                  56053 non-null  float64\n",
      " 60  blk                  56053 non-null  float64\n",
      " 61  pts                  56053 non-null  float64\n",
      " 62  player_id            56091 non-null  object \n",
      " 63  drafted              56091 non-null  float64\n",
      "dtypes: float64(49), int64(8), object(7)\n",
      "memory usage: 27.4+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d09df8d-65b8-49c6-a14e-20a70dcd6d96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team</th>\n",
       "      <th>conf</th>\n",
       "      <th>GP</th>\n",
       "      <th>Min_per</th>\n",
       "      <th>Ortg</th>\n",
       "      <th>usg</th>\n",
       "      <th>eFG</th>\n",
       "      <th>TS_per</th>\n",
       "      <th>ORB_per</th>\n",
       "      <th>DRB_per</th>\n",
       "      <th>...</th>\n",
       "      <th>dgbpm</th>\n",
       "      <th>oreb</th>\n",
       "      <th>dreb</th>\n",
       "      <th>treb</th>\n",
       "      <th>ast</th>\n",
       "      <th>stl</th>\n",
       "      <th>blk</th>\n",
       "      <th>pts</th>\n",
       "      <th>player_id</th>\n",
       "      <th>drafted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>56091</td>\n",
       "      <td>56091</td>\n",
       "      <td>56091.000000</td>\n",
       "      <td>56091.000000</td>\n",
       "      <td>56091.000000</td>\n",
       "      <td>56091.000000</td>\n",
       "      <td>56091.000000</td>\n",
       "      <td>56091.000000</td>\n",
       "      <td>56091.000000</td>\n",
       "      <td>56091.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>56047.000000</td>\n",
       "      <td>56053.000000</td>\n",
       "      <td>56053.000000</td>\n",
       "      <td>56053.000000</td>\n",
       "      <td>56053.000000</td>\n",
       "      <td>56053.000000</td>\n",
       "      <td>56053.000000</td>\n",
       "      <td>56053.000000</td>\n",
       "      <td>56091</td>\n",
       "      <td>56091.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>358</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23929</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Army</td>\n",
       "      <td>ACC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>06dc8dc2-888e-4941-9106-4798cddfb9d2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>209</td>\n",
       "      <td>2297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.411973</td>\n",
       "      <td>37.325229</td>\n",
       "      <td>91.858295</td>\n",
       "      <td>18.149265</td>\n",
       "      <td>44.575513</td>\n",
       "      <td>47.676882</td>\n",
       "      <td>5.575376</td>\n",
       "      <td>12.673716</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.442297</td>\n",
       "      <td>0.770611</td>\n",
       "      <td>1.892593</td>\n",
       "      <td>2.663204</td>\n",
       "      <td>1.073038</td>\n",
       "      <td>0.529475</td>\n",
       "      <td>0.282825</td>\n",
       "      <td>5.775381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.090542</td>\n",
       "      <td>28.061897</td>\n",
       "      <td>30.538819</td>\n",
       "      <td>6.204489</td>\n",
       "      <td>18.213813</td>\n",
       "      <td>17.414133</td>\n",
       "      <td>9.480239</td>\n",
       "      <td>10.878099</td>\n",
       "      <td>...</td>\n",
       "      <td>3.279438</td>\n",
       "      <td>0.738899</td>\n",
       "      <td>1.479148</td>\n",
       "      <td>2.099913</td>\n",
       "      <td>1.171148</td>\n",
       "      <td>0.469152</td>\n",
       "      <td>0.417754</td>\n",
       "      <td>4.953723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.097287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-100.984000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>84.100000</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>40.100000</td>\n",
       "      <td>43.930000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.728030</td>\n",
       "      <td>0.225800</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.222200</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.571400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>35.900000</td>\n",
       "      <td>97.100000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>47.700000</td>\n",
       "      <td>50.850000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>11.900000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.313051</td>\n",
       "      <td>0.545500</td>\n",
       "      <td>1.633300</td>\n",
       "      <td>2.259300</td>\n",
       "      <td>0.677400</td>\n",
       "      <td>0.424200</td>\n",
       "      <td>0.133300</td>\n",
       "      <td>4.482800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>62.200000</td>\n",
       "      <td>106.900000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>53.200000</td>\n",
       "      <td>56.060000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.066415</td>\n",
       "      <td>1.111100</td>\n",
       "      <td>2.758600</td>\n",
       "      <td>3.833300</td>\n",
       "      <td>1.533300</td>\n",
       "      <td>0.793100</td>\n",
       "      <td>0.366700</td>\n",
       "      <td>9.069000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>834.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>1576.600000</td>\n",
       "      <td>1385.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>78.985500</td>\n",
       "      <td>5.933300</td>\n",
       "      <td>11.545500</td>\n",
       "      <td>14.533300</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.258100</td>\n",
       "      <td>30.090900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         team   conf            GP       Min_per          Ortg           usg   \n",
       "count   56091  56091  56091.000000  56091.000000  56091.000000  56091.000000  \\\n",
       "unique    358     36           NaN           NaN           NaN           NaN   \n",
       "top      Army    ACC           NaN           NaN           NaN           NaN   \n",
       "freq      209   2297           NaN           NaN           NaN           NaN   \n",
       "mean      NaN    NaN     23.411973     37.325229     91.858295     18.149265   \n",
       "std       NaN    NaN     10.090542     28.061897     30.538819      6.204489   \n",
       "min       NaN    NaN      1.000000      0.000000      0.000000      0.000000   \n",
       "25%       NaN    NaN     16.000000      9.500000     84.100000     14.500000   \n",
       "50%       NaN    NaN     28.000000     35.900000     97.100000     18.100000   \n",
       "75%       NaN    NaN     31.000000     62.200000    106.900000     21.800000   \n",
       "max       NaN    NaN     41.000000     98.000000    834.000000     50.000000   \n",
       "\n",
       "                 eFG        TS_per       ORB_per       DRB_per  ...   \n",
       "count   56091.000000  56091.000000  56091.000000  56091.000000  ...  \\\n",
       "unique           NaN           NaN           NaN           NaN  ...   \n",
       "top              NaN           NaN           NaN           NaN  ...   \n",
       "freq             NaN           NaN           NaN           NaN  ...   \n",
       "mean       44.575513     47.676882      5.575376     12.673716  ...   \n",
       "std        18.213813     17.414133      9.480239     10.878099  ...   \n",
       "min         0.000000      0.000000      0.000000      0.000000  ...   \n",
       "25%        40.100000     43.930000      1.800000      8.400000  ...   \n",
       "50%        47.700000     50.850000      4.300000     11.900000  ...   \n",
       "75%        53.200000     56.060000      8.100000     16.000000  ...   \n",
       "max       150.000000    150.000000   1576.600000   1385.000000  ...   \n",
       "\n",
       "               dgbpm          oreb          dreb          treb           ast   \n",
       "count   56047.000000  56053.000000  56053.000000  56053.000000  56053.000000  \\\n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean       -0.442297      0.770611      1.892593      2.663204      1.073038   \n",
       "std         3.279438      0.738899      1.479148      2.099913      1.171148   \n",
       "min      -100.984000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        -1.728030      0.225800      0.700000      1.000000      0.222200   \n",
       "50%        -0.313051      0.545500      1.633300      2.259300      0.677400   \n",
       "75%         1.066415      1.111100      2.758600      3.833300      1.533300   \n",
       "max        78.985500      5.933300     11.545500     14.533300     10.000000   \n",
       "\n",
       "                 stl           blk           pts   \n",
       "count   56053.000000  56053.000000  56053.000000  \\\n",
       "unique           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN   \n",
       "mean        0.529475      0.282825      5.775381   \n",
       "std         0.469152      0.417754      4.953723   \n",
       "min         0.000000      0.000000      0.000000   \n",
       "25%         0.160000      0.000000      1.571400   \n",
       "50%         0.424200      0.133300      4.482800   \n",
       "75%         0.793100      0.366700      9.069000   \n",
       "max         4.000000      5.258100     30.090900   \n",
       "\n",
       "                                   player_id       drafted  \n",
       "count                                  56091  56091.000000  \n",
       "unique                                 23929           NaN  \n",
       "top     06dc8dc2-888e-4941-9106-4798cddfb9d2           NaN  \n",
       "freq                                       6           NaN  \n",
       "mean                                     NaN      0.009556  \n",
       "std                                      NaN      0.097287  \n",
       "min                                      NaN      0.000000  \n",
       "25%                                      NaN      0.000000  \n",
       "50%                                      NaN      0.000000  \n",
       "75%                                      NaN      0.000000  \n",
       "max                                      NaN      1.000000  \n",
       "\n",
       "[11 rows x 64 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c724f67a-5446-4803-bb6f-093b930f45f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc804613-12cb-47f8-8ad9-9ae37977fdd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yr                       292\n",
       "ht                        98\n",
       "num                     4690\n",
       "Rec_Rank               39055\n",
       "ast_tov                 4190\n",
       "rimmade                 6081\n",
       "rimmade_rimmiss         6081\n",
       "midmade                 6081\n",
       "midmade_midmiss         6081\n",
       "rim_ratio               9464\n",
       "mid_ratio               9688\n",
       "dunksmade               6081\n",
       "dunksmiss_dunksmade     6081\n",
       "dunks_ratio            30793\n",
       "pick                   54705\n",
       "drtg                      44\n",
       "adrtg                     44\n",
       "dporpag                   44\n",
       "stops                     44\n",
       "bpm                       44\n",
       "obpm                      44\n",
       "dbpm                      44\n",
       "gbpm                      44\n",
       "mp                        38\n",
       "ogbpm                     44\n",
       "dgbpm                     44\n",
       "oreb                      38\n",
       "dreb                      38\n",
       "treb                      38\n",
       "ast                       38\n",
       "stl                       38\n",
       "blk                       38\n",
       "pts                       38\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in the dataset\n",
    "missing_values = train_df.isnull().sum()\n",
    "\n",
    "# Display columns with missing values and their counts\n",
    "missing_values[missing_values > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca21ce75-be38-4a3e-9710-5833b9d748f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pick                   97.529015\n",
       "Rec_Rank               69.627926\n",
       "dunks_ratio            54.898290\n",
       "mid_ratio              17.271933\n",
       "rim_ratio              16.872582\n",
       "rimmade                10.841311\n",
       "rimmade_rimmiss        10.841311\n",
       "midmade                10.841311\n",
       "midmade_midmiss        10.841311\n",
       "dunksmade              10.841311\n",
       "dunksmiss_dunksmade    10.841311\n",
       "num                     8.361413\n",
       "ast_tov                 7.470004\n",
       "yr                      0.520583\n",
       "ht                      0.174716\n",
       "obpm                    0.078444\n",
       "dgbpm                   0.078444\n",
       "ogbpm                   0.078444\n",
       "gbpm                    0.078444\n",
       "dbpm                    0.078444\n",
       "adrtg                   0.078444\n",
       "bpm                     0.078444\n",
       "stops                   0.078444\n",
       "dporpag                 0.078444\n",
       "drtg                    0.078444\n",
       "mp                      0.067747\n",
       "oreb                    0.067747\n",
       "dreb                    0.067747\n",
       "treb                    0.067747\n",
       "ast                     0.067747\n",
       "stl                     0.067747\n",
       "blk                     0.067747\n",
       "pts                     0.067747\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the percentage of missing values for each column\n",
    "missing_percentage = (missing_values / len(train_df)) * 100\n",
    "\n",
    "# Display columns with missing value percentages\n",
    "missing_percentage[missing_percentage > 0].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed1d1ab-8789-445a-b9f6-f9793c32109a",
   "metadata": {},
   "source": [
    "Based on the percentage of missing values, we can make the following decisions:\n",
    "\n",
    "Drop Columns: We can drop columns pick and Rec_Rank as they have a high percentage of missing values (97.53% and 69.63% respectively). The dunks_ratio column also has over 50% missing values, so we can consider dropping it as well.\n",
    "\n",
    "Impute Values: For columns with a lower percentage of missing values, we can impute these values. For numerical columns, we'll use the median, and for categorical columns (like yr and ht), we'll use the mode.\n",
    "\n",
    "Drop Rows: Since the percentage of missing values for some columns is very low (less than 0.1%), we can drop those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eb9697d-061f-4a77-ace0-d909bb88d12b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. Drop columns with a high percentage of missing values\n",
    "columns_to_drop = ['pick', 'Rec_Rank', 'dunks_ratio']\n",
    "train_df = train_df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24a07756-aec9-4498-82cf-b7d650185c74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2. Impute missing values\n",
    "# For numerical columns\n",
    "numerical_columns_to_impute = ['ast_tov', 'rimmade', 'rimmade_rimmiss', 'midmade', 'midmade_midmiss', \n",
    "                               'dunksmade', 'dunksmiss_dunksmade', 'num', 'drtg', 'adrtg', 'dporpag', 'stops', \n",
    "                               'bpm', 'obpm', 'dbpm', 'gbpm', 'mp', 'ogbpm', 'dgbpm', 'oreb', 'dreb', 'treb', \n",
    "                               'ast', 'stl', 'blk', 'pts']\n",
    "#for column in numerical_columns_to_impute:\n",
    "#    train_df[column] = train_df[column].fillna(train_df[column].median())\n",
    "#\n",
    "# For categorical columns\n",
    "#categorical_columns_to_impute = ['yr', 'ht']\n",
    "#for column in categorical_columns_to_impute:\n",
    "#    train_df[column] = train_df[column].fillna(train_df[column].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9174d946-ea5b-4e94-9711-c9dc330d71b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': array([nan, '53', '5', '14', '22', '20', '34', '24', '54', '15', '13',\n",
       "        '10', '21', '32', '12', '51', '31', '33', '1', '45', '50', '3',\n",
       "        '23', '2', '4', '55', '35', '42', '25', '41', '52', '11', '40',\n",
       "        '30', '43', '0', '44', '23B', 2.0, 15.0, 11.0, 0.0, 5.0, 34.0,\n",
       "        24.0, 22.0, 1.0, 32.0, 23.0, 14.0, 20.0, 4.0, 33.0, 25.0, 40.0,\n",
       "        43.0, 3.0, 12.0, 10.0, 30.0, 21.0, 31.0, 13.0, 50.0, 44.0, 41.0,\n",
       "        35.0, 42.0, 45.0, 55.0, 54.0, 53.0, 52.0, 51.0, 8.0, 26.0, '99',\n",
       "        '4A', '31/24', '--', 99.0], dtype=object)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check unique values in the columns we assumed to be numerical\n",
    "non_numeric_values = {}\n",
    "\n",
    "for column in numerical_columns_to_impute:\n",
    "    try:\n",
    "        # Try converting the column to float\n",
    "        train_df[column].astype(float)\n",
    "    except ValueError:\n",
    "        # If there's an error, store the unique values of the column\n",
    "        non_numeric_values[column] = train_df[column].unique()\n",
    "\n",
    "non_numeric_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84f4a24-5ccd-4ae3-85fc-feb619ba913d",
   "metadata": {},
   "source": [
    "The num column, which we assumed to be numerical, contains non-numeric values such as '23B', 'None', '4A', '31/24', and '--'.\n",
    "\n",
    "1. Convert any value that can be cast to a number.\n",
    "2. Impute the non-numeric values and NaNs with the median of the numeric values.\n",
    "3. Proceed with imputation for the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6f1da75-a318-4b53-a0fb-8b9338d0a3c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yr            292\n",
       "ht             98\n",
       "rim_ratio    9464\n",
       "mid_ratio    9688\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert values in 'num' column to numeric where possible, setting errors='coerce' to replace non-numeric values with NaNs\n",
    "train_df['num'] = pd.to_numeric(train_df['num'], errors='coerce')\n",
    "\n",
    "# Impute NaNs in 'num' column with its median\n",
    "train_df['num'] = train_df['num'].fillna(train_df['num'].median())\n",
    "\n",
    "# Now, proceed with imputation for the other columns\n",
    "for column in numerical_columns_to_impute:\n",
    "    train_df[column] = train_df[column].fillna(train_df[column].median())\n",
    "\n",
    "# Check again for missing values\n",
    "missing_values_after_cleaning = train_df.isnull().sum()\n",
    "missing_values_after_cleaning[missing_values_after_cleaning > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7421e1-e730-476a-b9c8-db996027d001",
   "metadata": {},
   "source": [
    "We've handled the non-numeric values in the num column. However, there are still some missing values in the columns yr, ht, rim_ratio, and mid_ratio.\n",
    "\n",
    "We will impute yr and ht with their modes. For rim_ratio and mid_ratio, which are numerical columns, we'll use their medians for imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fe65eef-2818-4139-aa51-bbfe2ba15bd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Impute 'yr' and 'ht' with their modes\n",
    "train_df['yr'] = train_df['yr'].fillna(train_df['yr'].mode()[0])\n",
    "train_df['ht'] = train_df['ht'].fillna(train_df['ht'].mode()[0])\n",
    "\n",
    "# Impute 'rim_ratio' and 'mid_ratio' with their medians\n",
    "train_df['rim_ratio'] = train_df['rim_ratio'].fillna(train_df['rim_ratio'].median())\n",
    "train_df['mid_ratio'] = train_df['mid_ratio'].fillna(train_df['mid_ratio'].median())\n",
    "\n",
    "# Check again for missing values\n",
    "final_missing_values = train_df.isnull().sum()\n",
    "final_missing_values[final_missing_values > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d4c079-fb33-4e19-91d8-09c1c7cb776a",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7560ce1-a16d-49f1-a234-eeb944757959",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44872, 61), (11219, 61))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and validation sets (80% training, 20% validation)\n",
    "train_set, validation_set = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['drafted'])\n",
    "\n",
    "train_set.shape, validation_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1c3377-7175-401e-81b5-62ab9bc168c4",
   "metadata": {},
   "source": [
    "We will proceed with the Feature Engineering phase:\n",
    "\n",
    "1. Encoding Categorical Variables: We'll identify categorical columns and use one-hot encoding or label encoding to convert them into numerical values.\n",
    "2. Normalizing Numerical Features: This will help ensure that all features are on the same scale, which can be crucial for certain algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f35ab89-4498-4760-a58b-b15f143907f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((44872, 490), (11219, 490))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify categorical columns\n",
    "categorical_columns = train_set.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Exclude 'player_id' from the categorical columns as it's an identifier\n",
    "categorical_columns.remove('player_id')\n",
    "\n",
    "# One-hot encode the categorical columns\n",
    "train_encoded = pd.get_dummies(train_set, columns=categorical_columns, drop_first=True)\n",
    "validation_encoded = pd.get_dummies(validation_set, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "# Ensure that both training and validation datasets have the same columns after encoding\n",
    "missing_cols = set(train_encoded.columns) - set(validation_encoded.columns)\n",
    "for col in missing_cols:\n",
    "    validation_encoded[col] = 0\n",
    "\n",
    "# Align the order of columns in validation_encoded to match train_encoded\n",
    "validation_encoded = validation_encoded[train_encoded.columns]\n",
    "\n",
    "train_encoded.shape, validation_encoded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfb2098-35dd-4a45-a13e-378eb8e0db2c",
   "metadata": {},
   "source": [
    "Next we will normalize the numerical features. For this step, we'll use a MinMaxScaler to scale each feature to the range [0, 1]. \n",
    "\n",
    "We'll fit the scaler on the training data and then apply it to both the training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "999f55b4-97f9-4649-9c09-c2d8cc917567",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>Min_per</th>\n",
       "      <th>Ortg</th>\n",
       "      <th>usg</th>\n",
       "      <th>eFG</th>\n",
       "      <th>TS_per</th>\n",
       "      <th>ORB_per</th>\n",
       "      <th>DRB_per</th>\n",
       "      <th>AST_per</th>\n",
       "      <th>TO_per</th>\n",
       "      <th>...</th>\n",
       "      <th>ht_8-Jun</th>\n",
       "      <th>ht_8-May</th>\n",
       "      <th>ht_9-Jun</th>\n",
       "      <th>ht_9-May</th>\n",
       "      <th>ht_Apr-00</th>\n",
       "      <th>ht_Fr</th>\n",
       "      <th>ht_Jr</th>\n",
       "      <th>ht_Jul-00</th>\n",
       "      <th>ht_Jun-00</th>\n",
       "      <th>ht_So</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14530</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.606122</td>\n",
       "      <td>0.123741</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.312000</td>\n",
       "      <td>0.338533</td>\n",
       "      <td>0.003633</td>\n",
       "      <td>0.014916</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17837</th>\n",
       "      <td>0.600</td>\n",
       "      <td>0.333673</td>\n",
       "      <td>0.123501</td>\n",
       "      <td>0.356</td>\n",
       "      <td>0.355333</td>\n",
       "      <td>0.357267</td>\n",
       "      <td>0.011327</td>\n",
       "      <td>0.022068</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>0.725</td>\n",
       "      <td>0.586735</td>\n",
       "      <td>0.119784</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.298667</td>\n",
       "      <td>0.351733</td>\n",
       "      <td>0.015815</td>\n",
       "      <td>0.032693</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18612</th>\n",
       "      <td>0.725</td>\n",
       "      <td>0.592857</td>\n",
       "      <td>0.118705</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.342000</td>\n",
       "      <td>0.351000</td>\n",
       "      <td>0.018166</td>\n",
       "      <td>0.032693</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20107</th>\n",
       "      <td>0.425</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.090647</td>\n",
       "      <td>0.208</td>\n",
       "      <td>0.311333</td>\n",
       "      <td>0.311133</td>\n",
       "      <td>0.004061</td>\n",
       "      <td>0.005108</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 490 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          GP   Min_per      Ortg    usg       eFG    TS_per   ORB_per   \n",
       "14530  0.750  0.606122  0.123741  0.428  0.312000  0.338533  0.003633  \\\n",
       "17837  0.600  0.333673  0.123501  0.356  0.355333  0.357267  0.011327   \n",
       "3172   0.725  0.586735  0.119784  0.294  0.298667  0.351733  0.015815   \n",
       "18612  0.725  0.592857  0.118705  0.266  0.342000  0.351000  0.018166   \n",
       "20107  0.425  0.107143  0.090647  0.208  0.311333  0.311133  0.004061   \n",
       "\n",
       "        DRB_per  AST_per  TO_per  ...  ht_8-Jun  ht_8-May  ht_9-Jun  ht_9-May   \n",
       "14530  0.014916    0.262   0.146  ...       0.0       0.0       0.0       0.0  \\\n",
       "17837  0.022068    0.101   0.178  ...       0.0       0.0       0.0       0.0   \n",
       "3172   0.032693    0.050   0.216  ...       0.0       0.0       1.0       0.0   \n",
       "18612  0.032693    0.034   0.211  ...       0.0       0.0       0.0       0.0   \n",
       "20107  0.005108    0.138   0.434  ...       0.0       0.0       0.0       0.0   \n",
       "\n",
       "       ht_Apr-00  ht_Fr  ht_Jr  ht_Jul-00  ht_Jun-00  ht_So  \n",
       "14530        0.0    0.0    0.0        0.0        0.0    0.0  \n",
       "17837        0.0    0.0    0.0        0.0        0.0    0.0  \n",
       "3172         0.0    0.0    0.0        0.0        0.0    0.0  \n",
       "18612        0.0    0.0    0.0        0.0        0.0    0.0  \n",
       "20107        0.0    0.0    0.0        0.0        1.0    0.0  \n",
       "\n",
       "[5 rows x 490 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Exclude target and identifier columns from scaling\n",
    "columns_to_exclude = ['player_id', 'drafted']\n",
    "columns_to_scale = [col for col in train_encoded.columns if col not in columns_to_exclude]\n",
    "\n",
    "# Initialize and fit the scaler on the training data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_encoded[columns_to_scale])\n",
    "\n",
    "# Apply the scaler to the training and validation datasets\n",
    "train_encoded[columns_to_scale] = scaler.transform(train_encoded[columns_to_scale])\n",
    "validation_encoded[columns_to_scale] = scaler.transform(validation_encoded[columns_to_scale])\n",
    "\n",
    "# Check the first few rows of the normalized training dataset\n",
    "train_encoded.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73fccc5-cbc3-4be4-87ba-02584b253cd1",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9046b9e5-dc80-429e-87e9-dce05148ad35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9895869078137302"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Prepare features and target variable for training and validation datasets\n",
    "X_train = train_encoded.drop(columns=['player_id', 'drafted'])\n",
    "y_train = train_encoded['drafted']\n",
    "X_validation = validation_encoded.drop(columns=['player_id', 'drafted'])\n",
    "y_validation = validation_encoded['drafted']\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities on the validation dataset\n",
    "y_pred_prob = logreg.predict_proba(X_validation)[:, 1]\n",
    "\n",
    "# Calculate the AUROC score\n",
    "auroc_score = roc_auc_score(y_validation, y_pred_prob)\n",
    "auroc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90157477-a63a-4630-89c0-fe7891bbc913",
   "metadata": {},
   "source": [
    "# Generating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b7108a8-71a1-436d-8e89-93d305b009fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../data/raw/test.csv\")\n",
    "\n",
    "# Drop columns with a high percentage of missing values\n",
    "test_df = test_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Impute missing values\n",
    "# For numerical columns\n",
    "for column in numerical_columns_to_impute:\n",
    "    test_df[column] = test_df[column].fillna(test_df[column].median())\n",
    "\n",
    "# For categorical columns\n",
    "#for column in categorical_columns_to_impute:\n",
    "#    test_df[column] = test_df[column].fillna(test_df[column].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d14ad1b7-c558-4e2e-9f36-112a7f81706c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert values in 'num' column to numeric where possible, setting errors='coerce' to replace non-numeric values with NaNs\n",
    "test_df['num'] = pd.to_numeric(test_df['num'], errors='coerce')\n",
    "\n",
    "# Impute NaNs in 'num' column with its median\n",
    "test_df['num'] = test_df['num'].fillna(test_df['num'].median())\n",
    "\n",
    "# Impute 'rim_ratio' and 'mid_ratio' with their medians\n",
    "test_df['rim_ratio'] = test_df['rim_ratio'].fillna(train_df['rim_ratio'].median())\n",
    "test_df['mid_ratio'] = test_df['mid_ratio'].fillna(train_df['mid_ratio'].median())\n",
    "\n",
    "# Now, proceed with imputation for the other columns\n",
    "for column in numerical_columns_to_impute:\n",
    "    test_df[column] = test_df[column].fillna(test_df[column].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12a2a2da-3f3d-4fb8-bae7-e80707e88a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One-hot encode the categorical columns\n",
    "test_encoded = pd.get_dummies(test_df, columns=categorical_columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "97dfb264-f091-4259-9ece-ff447499c9a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure that both training and test datasets have the same columns after encoding\n",
    "missing_cols = set(train_encoded.columns) - set(test_encoded.columns)\n",
    "for col in missing_cols:\n",
    "    test_encoded[col] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7cf43f74-4f46-4044-867e-92a7d41eaaab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Align the order of columns in test_encoded to match train_encoded\n",
    "test_encoded = test_encoded[train_encoded.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30c6df40-515a-4e91-8fba-2037525d085c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply the scaler to the test dataset\n",
    "test_encoded[columns_to_scale] = scaler.transform(test_encoded[columns_to_scale])\n",
    "\n",
    "# Prepare features for test dataset\n",
    "X_test = test_encoded.drop(columns=['player_id', 'drafted'])\n",
    "\n",
    "# Generate predictions on the test dataset\n",
    "y_test_pred_prob = logreg.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1fa06c1b-95dc-4399-adeb-6815fa6d8de4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame with player_id and predictions\n",
    "predictions_df = pd.DataFrame({'player_id': test_encoded['player_id'], 'drafted': y_test_pred_prob})\n",
    "\n",
    "# Generate a csv file with predictions\n",
    "predictions_df.to_csv('predictions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
